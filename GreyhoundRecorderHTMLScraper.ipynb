{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.thegreyhoundrecorder.com.au\"\n",
    "results_url = \"https://www.thegreyhoundrecorder.com.au/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organise by tracks? record dates?\n",
    "def get_pages_soups(urls: list[str]):\n",
    "    soups = []\n",
    "    \n",
    "    for url in urls:\n",
    "        r = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "        with urlopen(r) as webpage:\n",
    "            content = webpage.read().decode()\n",
    "            soups.append(BeautifulSoup(content))\n",
    "\n",
    "    return soups\n",
    "\n",
    "def get_page_soup(url: str):\n",
    "    r = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "    with urlopen(r) as webpage:\n",
    "        content = webpage.read().decode()\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race refers to dogContainer elements (one for each race in a meeting)\n",
    "def extract_distance(race):\n",
    "    race_title = race.find(attrs={\"class\": \"font14\"}).text\n",
    "    return race_title.split()[-1].strip(\"()\")\n",
    "\n",
    "def extract_race_grade(race):\n",
    "    race_header = race.select(\".runnerFormHeader div\")\n",
    "    race_class =  race_header[1].text.split('$')[0]\n",
    "    return race_class[:-3]\n",
    "\n",
    "def extract_fastest_split(race):\n",
    "    race_header = race.select(\".runnerFormHeader div\")\n",
    "    return float(race_header[2].text.split()[1].strip(','))\n",
    "\n",
    "def extract_win_time(race):\n",
    "    first_row = race.select(\".runnerContainer .runnerSubDetails div\")[1].text\n",
    "    time = first_row.strip()[4:]\n",
    "    return float(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_races(soup):\n",
    "    return soup.select(\".dogContainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes times organised by distance only\n",
    "def scrape_times(races):\n",
    "    race_time_dict = {}\n",
    "    sect_time_dict = {}\n",
    "\n",
    "    for race in races:\n",
    "        distance = extract_distance(race)\n",
    "        fastest_split = extract_fastest_split(race)\n",
    "        win_time = extract_win_time(race)\n",
    "\n",
    "        if distance not in race_time_dict:\n",
    "            race_time_dict[distance] = []\n",
    "            sect_time_dict[distance] = []\n",
    "\n",
    "        race_time_dict[distance].append(win_time)\n",
    "        sect_time_dict[distance].append(fastest_split)\n",
    "\n",
    "    return race_time_dict, sect_time_dict\n",
    "\n",
    "# scrapes times organised by distance and grade\n",
    "def scrape_times_by_grade(races):\n",
    "    race_time_dict = {}\n",
    "    sect_time_dict = {}\n",
    "    \n",
    "    for race in races:\n",
    "        distance = extract_distance(race)\n",
    "        grade = extract_race_grade(race)\n",
    "        fastest_split = extract_fastest_split(race)\n",
    "        win_time = extract_win_time(race)\n",
    "\n",
    "        if distance not in race_time_dict:\n",
    "            race_time_dict[distance] = {}\n",
    "            sect_time_dict[distance] = {}\n",
    "\n",
    "        if grade not in race_time_dict[distance]:\n",
    "            race_time_dict[distance][grade] = []\n",
    "            sect_time_dict[distance][grade] = []\n",
    "\n",
    "        race_time_dict[distance][grade].append(win_time)\n",
    "        sect_time_dict[distance][grade].append(fastest_split)\n",
    "\n",
    "    return race_time_dict, sect_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_page_soups_by_track():\n",
    "    track_urls = {}\n",
    "\n",
    "    results_page_soup = get_page_soup(results_url)\n",
    "\n",
    "    # all results by track\n",
    "    results_by_track = results_page_soup.select(\".row.resultTracks a\")\n",
    "    \n",
    "    # add all urls of results in track page\n",
    "    for results_tag in results_by_track:\n",
    "        track_result_page_soup = get_page_soup(base_url + results_tag[\"href\"])\n",
    "        result_links = track_result_page_soup.select(\".results.table-striped a\")\n",
    "        track_urls[results_tag.text] = [base_url + link[\"href\"] for link in result_links]\n",
    "\n",
    "    # curr structure\n",
    "    # {track_name: [result_pages_soups]}\n",
    "    return {track:get_pages_soups(urls) for track, urls in track_urls.items()}\n",
    "\n",
    "def get_result_page_links_by_track():\n",
    "    track_urls = {}\n",
    "\n",
    "    base_url = \"https://www.thegreyhoundrecorder.com.au\"\n",
    "    results_url = \"https://www.thegreyhoundrecorder.com.au/results/\"\n",
    "    results_page_soup = get_page_soup(results_url)\n",
    "\n",
    "    # all results by track\n",
    "    results_by_track = results_page_soup.select(\".row.resultTracks a\")\n",
    "    \n",
    "    # add all urls of results in track page\n",
    "    for results_tag in results_by_track:\n",
    "        track_result_page_soup = get_page_soup(base_url + results_tag[\"href\"])\n",
    "        result_links = track_result_page_soup.select(\".results.table-striped a\")\n",
    "        track_urls[results_tag.text] = [base_url + link[\"href\"] for link in result_links]\n",
    "\n",
    "    return track_urls\n",
    "\n",
    "def get_single_track_results_links(url: str):\n",
    "    soup = get_page_soup(url)\n",
    "\n",
    "    result_links = soup.select(\".results.table-striped a\")\n",
    "    track_urls = [base_url + link_tag[\"href\"] for link_tag in result_links]\n",
    "\n",
    "    return track_urls\n",
    "\n",
    "# get standard time for one track\n",
    "def get_track_standard_time(track_soups):\n",
    "    track_standard_race_times = {}\n",
    "    track_standard_sect_times = {}\n",
    "\n",
    "    race_times_by_distance = {}\n",
    "    sect_times_by_distance = {}\n",
    "\n",
    "    for meet in track_soups:\n",
    "        races = get_races(meet)\n",
    "        race_times_dict, sect_times_dict = scrape_times(races)\n",
    "\n",
    "        for distance in race_times_dict:\n",
    "            if distance not in race_times_by_distance:\n",
    "                race_times_by_distance[distance] = []\n",
    "                sect_times_by_distance[distance] = []\n",
    "\n",
    "        for distance in race_times_dict:\n",
    "            race_times_by_distance[distance] += race_times_dict[distance]\n",
    "            sect_times_by_distance[distance] += sect_times_dict[distance]\n",
    "\n",
    "    for distance in race_times_by_distance:\n",
    "        race_times_list = race_times_by_distance[distance]\n",
    "        sect_times_list = sect_times_by_distance[distance]\n",
    "\n",
    "        track_standard_race_times[distance] = sum(race_times_list) / len(race_times_list)\n",
    "        track_standard_sect_times[distance] = sum(sect_times_list) / len(sect_times_list)\n",
    "\n",
    "    return track_standard_race_times, track_standard_sect_times\n",
    "    \n",
    "\n",
    "# for multiple tracks        \n",
    "# track_soups is dictionary of results' page html soups by track \n",
    "def get_standard_times(track_soups):\n",
    "    track_standard_race_times = {track:{} for track in track_soups}\n",
    "    track_standard_sect_times = {track:{} for track in track_soups}\n",
    "\n",
    "    for track in track_soups:\n",
    "        race_times_by_distance = {}\n",
    "        sect_times_by_distance = {}\n",
    "\n",
    "        for meet in track_soups[track]:\n",
    "            races = get_races(meet)\n",
    "            race_times_dict, sect_times_dict = scrape_times(races)\n",
    "            \n",
    "            for distance in race_times_dict:\n",
    "                if distance not in race_times_by_distance:\n",
    "                    race_times_by_distance[distance] = []\n",
    "                    sect_times_by_distance[distance] = []\n",
    "\n",
    "            for distance in race_times_dict:\n",
    "                race_times_by_distance[distance] += race_times_dict[distance]\n",
    "                sect_times_by_distance[distance] += sect_times_dict[distance]\n",
    "\n",
    "        for distance in race_times_by_distance:\n",
    "            race_times_list = race_times_by_distance[distance]\n",
    "            sect_times_list = sect_times_by_distance[distance]\n",
    "\n",
    "            track_standard_race_times[track][distance] = sum(race_times_list) / len(race_times_list)\n",
    "            track_standard_sect_times[track][distance] = sum(sect_times_list) / len(sect_times_list)\n",
    "\n",
    "    return track_standard_race_times, track_standard_sect_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_links = get_single_track_results_links(\"https://www.thegreyhoundrecorder.com.au/results/ballarat/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_soups = get_pages_soups(track_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'N/A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kaleb\\Documents\\GreyhoundModel\\GreyhoundRecorderHTMLScraper.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000014?line=0'>1</a>\u001b[0m race_standard_times, sect_standard_times \u001b[39m=\u001b[39m get_track_standard_time(link_soups)\n",
      "\u001b[1;32mc:\\Users\\kaleb\\Documents\\GreyhoundModel\\GreyhoundRecorderHTMLScraper.ipynb Cell 7'\u001b[0m in \u001b[0;36mget_track_standard_time\u001b[1;34m(track_soups)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000005?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m meet \u001b[39min\u001b[39;00m track_soups:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000005?line=53'>54</a>\u001b[0m     races \u001b[39m=\u001b[39m get_races(meet)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000005?line=54'>55</a>\u001b[0m     race_times_dict, sect_times_dict \u001b[39m=\u001b[39m scrape_times(races)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000005?line=56'>57</a>\u001b[0m     \u001b[39mfor\u001b[39;00m distance \u001b[39min\u001b[39;00m race_times_dict:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000005?line=57'>58</a>\u001b[0m         \u001b[39mif\u001b[39;00m distance \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m race_times_by_distance:\n",
      "\u001b[1;32mc:\\Users\\kaleb\\Documents\\GreyhoundModel\\GreyhoundRecorderHTMLScraper.ipynb Cell 6'\u001b[0m in \u001b[0;36mscrape_times\u001b[1;34m(races)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000004?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m race \u001b[39min\u001b[39;00m races:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000004?line=6'>7</a>\u001b[0m     distance \u001b[39m=\u001b[39m extract_distance(race)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000004?line=7'>8</a>\u001b[0m     fastest_split \u001b[39m=\u001b[39m extract_fastest_split(race)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000004?line=8'>9</a>\u001b[0m     win_time \u001b[39m=\u001b[39m extract_win_time(race)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000004?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m distance \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m race_time_dict:\n",
      "\u001b[1;32mc:\\Users\\kaleb\\Documents\\GreyhoundModel\\GreyhoundRecorderHTMLScraper.ipynb Cell 4'\u001b[0m in \u001b[0;36mextract_fastest_split\u001b[1;34m(race)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000002?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_fastest_split\u001b[39m(race):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000002?line=11'>12</a>\u001b[0m     race_header \u001b[39m=\u001b[39m race\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39m.runnerFormHeader div\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kaleb/Documents/GreyhoundModel/GreyhoundRecorderHTMLScraper.ipynb#ch0000002?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39;49m(race_header[\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49msplit()[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mstrip(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'N/A'"
     ]
    }
   ],
   "source": [
    "race_standard_times, sect_standard_times = get_track_standard_time(link_soups)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f39ac08f080bed9f65db098af1f1e9c9b34242fc0b2e37b56675f3f4db02c03"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
