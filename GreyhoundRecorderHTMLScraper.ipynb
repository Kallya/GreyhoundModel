{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.thegreyhoundrecorder.com.au\"\n",
    "results_url = \"https://www.thegreyhoundrecorder.com.au/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organise by tracks? record dates?\n",
    "def get_pages_soups(urls: list[str]):\n",
    "    soups = []\n",
    "    \n",
    "    for url in urls:\n",
    "        r = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "        with urlopen(r) as webpage:\n",
    "            content = webpage.read().decode()\n",
    "            soups.append(BeautifulSoup(content))\n",
    "\n",
    "    return soups\n",
    "\n",
    "def get_page_soup(url: str):\n",
    "    r = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "    with urlopen(r) as webpage:\n",
    "        content = webpage.read().decode()\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race refers to dogContainer elements (one for each race in a meeting)\n",
    "def extract_distance(race):\n",
    "    race_title = race.find(attrs={\"class\": \"font14\"}).text\n",
    "    return race_title.split()[-1].strip(\"()\")\n",
    "\n",
    "def extract_race_grade(race):\n",
    "    race_header = race.select(\".runnerFormHeader div\")\n",
    "    race_class =  race_header[1].text.split('$')[0]\n",
    "    return race_class[:-3]\n",
    "\n",
    "def extract_fastest_split(race):\n",
    "    race_header = race.select(\".runnerFormHeader div\")\n",
    "    return float(race_header[2].text.split()[1].strip(','))\n",
    "\n",
    "def extract_win_time(race):\n",
    "    first_row = race.select(\".runnerContainer .runnerSubDetails div\")[1].text\n",
    "    time = first_row.strip()[4:]\n",
    "    return float(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_races(soup):\n",
    "    return soup.select(\".dogContainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes times organised by distance only\n",
    "def scrape_times(races):\n",
    "    race_time_dict = {}\n",
    "    sect_time_dict = {}\n",
    "\n",
    "    for race in races:\n",
    "        distance = extract_distance(race)\n",
    "        fastest_split = extract_fastest_split(race)\n",
    "        win_time = extract_win_time(race)\n",
    "\n",
    "        if distance not in race_time_dict:\n",
    "            race_time_dict[distance] = []\n",
    "            sect_time_dict[distance] = []\n",
    "\n",
    "        race_time_dict[distance].append(win_time)\n",
    "        sect_time_dict[distance].append(fastest_split)\n",
    "\n",
    "    return race_time_dict, sect_time_dict\n",
    "\n",
    "# scrapes times organised by distance and grade\n",
    "def scrape_times_by_grade(races):\n",
    "    race_time_dict = {}\n",
    "    sect_time_dict = {}\n",
    "    \n",
    "    for race in races:\n",
    "        distance = extract_distance(race)\n",
    "        grade = extract_race_grade(race)\n",
    "        fastest_split = extract_fastest_split(race)\n",
    "        win_time = extract_win_time(race)\n",
    "\n",
    "        if distance not in race_time_dict:\n",
    "            race_time_dict[distance] = {}\n",
    "            sect_time_dict[distance] = {}\n",
    "\n",
    "        if grade not in race_time_dict[distance]:\n",
    "            race_time_dict[distance][grade] = []\n",
    "            sect_time_dict[distance][grade] = []\n",
    "\n",
    "        race_time_dict[distance][grade].append(win_time)\n",
    "        sect_time_dict[distance][grade].append(fastest_split)\n",
    "\n",
    "    return race_time_dict, sect_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_page_soups_by_track():\n",
    "    track_urls = {}\n",
    "\n",
    "    results_page_soup = get_page_soup(results_url)\n",
    "\n",
    "    # all results by track\n",
    "    results_by_track = results_page_soup.select(\".row.resultTracks a\")\n",
    "    \n",
    "    # add all urls of results in track page\n",
    "    for results_tag in results_by_track:\n",
    "        track_result_page_soup = get_page_soup(base_url + results_tag[\"href\"])\n",
    "        result_links = track_result_page_soup.select(\".results.table-striped a\")\n",
    "        track_urls[results_tag.text] = [base_url + link[\"href\"] for link in result_links]\n",
    "\n",
    "    # curr structure\n",
    "    # {track_name: [result_pages_soups]}\n",
    "    return {track:get_pages_soups(urls) for track, urls in track_urls.items()}\n",
    "\n",
    "def get_result_page_links_by_track():\n",
    "    track_urls = {}\n",
    "\n",
    "    base_url = \"https://www.thegreyhoundrecorder.com.au\"\n",
    "    results_url = \"https://www.thegreyhoundrecorder.com.au/results/\"\n",
    "    results_page_soup = get_page_soup(results_url)\n",
    "\n",
    "    # all results by track\n",
    "    results_by_track = results_page_soup.select(\".row.resultTracks a\")\n",
    "    \n",
    "    # add all urls of results in track page\n",
    "    for results_tag in results_by_track:\n",
    "        track_result_page_soup = get_page_soup(base_url + results_tag[\"href\"])\n",
    "        result_links = track_result_page_soup.select(\".results.table-striped a\")\n",
    "        track_urls[results_tag.text] = [base_url + link[\"href\"] for link in result_links]\n",
    "\n",
    "    return track_urls\n",
    "\n",
    "def get_single_track_results_links(url: str):\n",
    "    soup = get_page_soup(url)\n",
    "\n",
    "    result_links = soup.select(\".results.table-striped a\")\n",
    "    track_urls = [base_url + link_tag[\"href\"] for link_tag in result_links]\n",
    "\n",
    "    return track_urls\n",
    "\n",
    "# get standard time for one track\n",
    "def get_track_standard_time(track_soups):\n",
    "    track_standard_race_times = {}\n",
    "    track_standard_sect_times = {}\n",
    "\n",
    "    race_times_by_distance = {}\n",
    "    sect_times_by_distance = {}\n",
    "\n",
    "    for meet in track_soups:\n",
    "        races = get_races(meet)\n",
    "        race_times_dict, sect_times_dict = scrape_times(races)\n",
    "\n",
    "        for distance in race_times_dict:\n",
    "            if distance not in race_times_by_distance:\n",
    "                race_times_by_distance[distance] = []\n",
    "                sect_times_by_distance[distance] = []\n",
    "\n",
    "        for distance in race_times_dict:\n",
    "            race_times_by_distance[distance] += race_times_dict[distance]\n",
    "            sect_times_by_distance[distance] += sect_times_dict[distance]\n",
    "\n",
    "    for distance in race_times_by_distance:\n",
    "        race_times_list = race_times_by_distance[distance]\n",
    "        sect_times_list = sect_times_by_distance[distance]\n",
    "\n",
    "        track_standard_race_times[distance] = sum(race_times_list) / len(race_times_list)\n",
    "        track_standard_sect_times[distance] = sum(sect_times_list) / len(sect_times_list)\n",
    "\n",
    "    return track_standard_race_times, track_standard_sect_times\n",
    "    \n",
    "\n",
    "# for multiple tracks        \n",
    "# track_soups is dictionary of results' page html soups by track \n",
    "def get_standard_times(track_soups):\n",
    "    track_standard_race_times = {track:{} for track in track_soups}\n",
    "    track_standard_sect_times = {track:{} for track in track_soups}\n",
    "\n",
    "    for track in track_soups:\n",
    "        race_times_by_distance = {}\n",
    "        sect_times_by_distance = {}\n",
    "\n",
    "        for meet in track_soups[track]:\n",
    "            races = get_races(meet)\n",
    "            race_times_dict, sect_times_dict = scrape_times(races)\n",
    "            \n",
    "            for distance in race_times_dict:\n",
    "                if distance not in race_times_by_distance:\n",
    "                    race_times_by_distance[distance] = []\n",
    "                    sect_times_by_distance[distance] = []\n",
    "\n",
    "            for distance in race_times_dict:\n",
    "                race_times_by_distance[distance] += race_times_dict[distance]\n",
    "                sect_times_by_distance[distance] += sect_times_dict[distance]\n",
    "\n",
    "        for distance in race_times_by_distance:\n",
    "            race_times_list = race_times_by_distance[distance]\n",
    "            sect_times_list = sect_times_by_distance[distance]\n",
    "\n",
    "            track_standard_race_times[track][distance] = sum(race_times_list) / len(race_times_list)\n",
    "            track_standard_sect_times[track][distance] = sum(sect_times_list) / len(sect_times_list)\n",
    "\n",
    "    return track_standard_race_times, track_standard_sect_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_times_single_track(result_soups):\n",
    "    race_times = []\n",
    "    sect_times = []\n",
    "\n",
    "    for soup in result_soups:\n",
    "        races = get_races(soup)\n",
    "        times = scrape_times_by_grade(races)\n",
    "        \n",
    "        race_times.append(times[0])\n",
    "        sect_times.append(sect_times[1])\n",
    "\n",
    "    all_race_time_dict = race_times[0]\n",
    "    all_sect_time_dict = sect_times[0]\n",
    "\n",
    "# combine the times organised by grade\n",
    "# for a distance\n",
    "# e.g. {'390m': {'Maiden': [22.63], ...}}\n",
    "def combine_grade_time_dicts(times_by_grade1, times_by_grade2):\n",
    "    for grade in times_by_grade1:\n",
    "        if grade in times_by_grade2:\n",
    "            times_by_grade1[grade] += times_by_grade2[grade]\n",
    "    \n",
    "    return (times_by_grade2 | times_by_grade1)\n",
    "\n",
    "def combine_distance_time_dicts(times_by_distance1, times_by_distance2):\n",
    "    for distance in times_by_distance1:\n",
    "        if distance in times_by_distance2:\n",
    "            times_by_distance1[distance] = combine_grade_time_dicts(times_by_distance1[distance], times_by_distance2[distance])\n",
    "\n",
    "    return (times_by_distance2 | times_by_distance1)\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f39ac08f080bed9f65db098af1f1e9c9b34242fc0b2e37b56675f3f4db02c03"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
